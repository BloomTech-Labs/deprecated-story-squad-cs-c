{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing-Pipeline.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fsrO7Wz4Vc3"
      },
      "source": [
        "!pip install fastapi pyngrok uvicorn\n",
        "!pip install nest_asyncio\n",
        "!pip install tesseract\n",
        "# SUDO APT INSTALL FOR LINUX\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "!pip install python-multipart\n",
        "!pip install pytesseract\n",
        "!pip install python-multipart\n",
        "pip install textstat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B--9j4So4NC2"
      },
      "source": [
        "import numpy as np\n",
        "import sys, os, setuptools, tokenize\n",
        "from fastapi import FastAPI, UploadFile, File\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from starlette.requests import Request\n",
        "import io\n",
        "import cv2\n",
        "import pytesseract\n",
        "from pydantic import BaseModel\n",
        "import nest_asyncio\n",
        "import textstat.textstat\n",
        "from google.colab.patches import cv2_imshow\n",
        "nest_asyncio.apply()\n",
        "\n",
        "def read_img(img):\n",
        "  pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'\n",
        "  text = pytesseract.image_to_string(img)\n",
        "  return(text)\n",
        " \n",
        "app = FastAPI()\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "class ImageType(BaseModel):\n",
        "  url: str\n",
        "\n",
        "@app.post(\"/predict/\") \n",
        "def prediction(request: Request, \n",
        "  file: bytes = File(...)):\n",
        "  # If we're dealing with a post request\n",
        "  if request.method == \"POST\":\n",
        "    image_stream = io.BytesIO(file)\n",
        "    image_stream.seek(0)\n",
        "    file_bytes = np.asarray(bytearray(image_stream.read()), dtype=np.uint8)\n",
        "    frame = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)\n",
        "\n",
        "    # blur\n",
        "    blur = cv2.GaussianBlur(frame, (3,3), 0)\n",
        "\n",
        "    # convert to hsv and get saturation channel\n",
        "    sat = cv2.cvtColor(blur, cv2.COLOR_BGR2HSV)[:,:,1]\n",
        "\n",
        "    # threshold saturation channel\n",
        "    thresh = cv2.threshold(sat, 50, 255, cv2.THRESH_BINARY)[1]\n",
        "\n",
        "    # apply morphology close and open to make mask\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9,9))\n",
        "    morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
        "    mask = cv2.morphologyEx(morph, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "\n",
        "    # do OTSU threshold to get circuit image\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    otsu = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
        "\n",
        "    # write black to otsu image where mask is black\n",
        "    otsu_result = otsu.copy()\n",
        "    otsu_result[mask==0] = 0\n",
        "\n",
        "\n",
        "    # Now we use pytesseract to extract the text\n",
        "    label = read_img(otsu)\n",
        "\n",
        "    sample_story = label\n",
        "    cv2_imshow(otsu)\n",
        "    return textstat.textstat.flesch_kincaid_grade(sample_story)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjtHLU_X4dMI"
      },
      "source": [
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "url = ngrok.connect(port=8000)\n",
        "print('Public URL:', url)\n",
        "uvicorn.run(app, port=8000)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}